{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import math\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spectrum import clear_spectrum\n",
    "from traffic import generate_traffic\n",
    "from algorithms.utils import k_shortest_paths\n",
    "\n",
    "from algorithms.genetic_algorithm import GenAlg\n",
    "from algorithms.first_fit import k_SP_FF_RSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 9\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the topology\n",
    "TOPOLOGY = 'National' # 'Continental'\n",
    "# Select spectrum partitioning\n",
    "PARTITIONING = 'Hard' # 'Hard'\n",
    "# Select the algorithm to be used\n",
    "ALGORITHM = 'FF' # 'FF'\n",
    "\n",
    "# Density of the network (wrt fully connected graph)\n",
    "density = 0.5\n",
    "# Capacity of the network links (THz)\n",
    "CAPACITY = 4.4*(10**3) \n",
    "# Slice width (GHz) (used for section of 50 GHz (2 slices) or 75 GHz (3 slices))\n",
    "slot_width = 25 \n",
    "# Number of slots in the network\n",
    "num_slots = int(CAPACITY/slot_width)\n",
    "\n",
    "# Initial, maximum and relative number of demands\n",
    "num_demands_init = 350 \n",
    "num_demands_max = 2000\n",
    "num_demands_delta = 50\n",
    "# Number of shortest paths to be considered\n",
    "k = 4 \n",
    "# Number of Monte Carlo simulations\n",
    "MC = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set secondary parameters according to the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### TOPOLOGY PARAMETERS #######\n",
    "if TOPOLOGY == 'Continental':\n",
    "    print('Continental topology')\n",
    "    # Continental topology\n",
    "    Nodes = 7 # Number of nodes\n",
    "    d_min, d_max = 400, 1100 # Min and max distances between nodes\n",
    "    d_max_req, d_avg_req = 1000, 300 # Max and average distances (REQUIRED)\n",
    "    # A requirement for the number of links\n",
    "    req_links = lambda x: x>=20 \n",
    "    \n",
    "elif TOPOLOGY == 'National':\n",
    "    print('National topology')\n",
    "    # National topology\n",
    "    Nodes = 4 # Number of nodes\n",
    "    d_min, d_max = 150, 450 # Min and max distances between nodes\n",
    "    d_max_req, d_avg_req = 400, 150 # Max and average distances (REQUIRED)    \n",
    "    # A requirement for the number of links\n",
    "    req_links = lambda x: x<=20 \n",
    "\n",
    "if PARTITIONING == 'Soft':\n",
    "    print('Soft partitioning')\n",
    "    border = None\n",
    "    last_slot_75 = None\n",
    "elif PARTITIONING == 'Hard':\n",
    "    print('Hard partitioning')\n",
    "    # Percent of the spectrum belongs to 75 GHz, the rest is to 50 GHz\n",
    "    border = 0.1 \n",
    "    # Round to closest 3 slots\n",
    "    last_slot_75 = 3*ceil(num_slots*border/3)\n",
    "\n",
    "if ALGORITHM == 'GA':\n",
    "    print('Genetic Algorithm')\n",
    "    import logging\n",
    "    # Disable logging output for the 'jmetal' logger\n",
    "    logging.getLogger('jmetal').setLevel(logging.CRITICAL)\n",
    "    algorithm = GenAlg\n",
    "elif ALGORITHM == 'FF':\n",
    "    print('First Fit Algorithm')\n",
    "    algorithm = k_SP_FF_RSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the distances between nodes as weights of the edges\n",
    "distances = np.random.randint(d_min, d_max, size=(Nodes,Nodes))\n",
    "\n",
    "# Generate the adjacency matrix\n",
    "mask = np.random.choice([0, 1], size=(Nodes,Nodes), p=[1-density, density])\n",
    "a = np.multiply(distances, mask)\n",
    "\n",
    "# Force the matrix to be symmetric\n",
    "A = ((a + a.T)/2).astype(int)\n",
    "# Remove self loops\n",
    "np.fill_diagonal(A,0)\n",
    "\n",
    "# Create the graph\n",
    "G = nx.DiGraph(A)\n",
    "    \n",
    "N, E = list(G.nodes()), list(G.edges())\n",
    "weights = nx.get_edge_attributes(G,'weight')# set of lengths of each edge\n",
    "weight_avg = np.mean(list(weights.values()))\n",
    "weight_max = np.max(list(weights.values()))\n",
    "\n",
    "# Check if the topology satisfies the requirements\n",
    "print('Nodes:', N)\n",
    "print('Edges:', E)\n",
    "print('Is the number of links enough?', req_links(len(E)), f'(Number of links: {len(E)})')\n",
    "print(f'Avg. distance: {weight_avg:.2f}km, Max. distance: {weight_max}km')\n",
    "print(f'Avg. distance (REQUIRED): ~{d_avg_req} km, Max. distance (REQUIRED): ~{d_max_req}km')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the graph and the adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Adjacency matrix:\\n', A)\n",
    "pos=nx.spring_layout(G, seed=seed)\n",
    "nx.draw(G, pos, with_labels=True, font_weight='bold')\n",
    "edge_weight = nx.get_edge_attributes(G,'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels = edge_weight)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(array):\n",
    "    \"\"\"Compute the confidence interval\"\"\"\n",
    "    return np.std(array) * 1.96 / math.sqrt(len(array)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms simulation\n",
    "\n",
    "Simulation is performed over a constantly increasing number of demands. For each of the number of demands, the results of multiple Monte-Carlo simulations are averaged and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store the results\n",
    "columns = ['traff_mean', 'num_demands', 'bp_mean', 'bp_conf', 'cost_mean', 'cost_conf']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "start_time0 = time.time()\n",
    "# Loop over the number of demands\n",
    "for num_demands in range(num_demands_init, num_demands_max, num_demands_delta):\n",
    "    print(num_demands)\n",
    "    traffic, bp, cost = [], [], []\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Loop over the Monte Carlo simulations\n",
    "    for m in range(MC):\n",
    "        # Generate the traffic demands\n",
    "        D = generate_traffic(num_demands, Nodes)\n",
    "        # Compute the total offered traffic (in Gbps)\n",
    "        offered_traff = sum(sum(x) for x in D.values()) \n",
    "        traffic.append(offered_traff)\n",
    "        clear_spectrum(G, num_slots)\n",
    "\n",
    "        # Compute the k shortest paths\n",
    "        paths_dict, len_p = k_shortest_paths(G, N, k)\n",
    "        # Compute the blocking probability and the number of regenerators \n",
    "        # by solving the RSA problem with selected algorithm\n",
    "        num_reg, lost_traffic = algorithm(G, k, paths_dict, len_p, D, last_slot_75, PARTITIONING)\n",
    "        \n",
    "        # Compute the blocking probability\n",
    "        bp.append(lost_traffic/offered_traff)\n",
    "        cost.append(num_reg)\n",
    "\n",
    "    # Store the results \n",
    "    bp_current = np.mean(bp)   \n",
    "    row = [offered_traff, num_demands, np.mean(bp), confidence(bp), np.mean(cost), confidence(cost)]    \n",
    "    df.loc[len(df)] = row\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"Time to compute a demand is {:.2f} min\".format((end_time-start_time)/60))\n",
    "    print(bp_current)\n",
    "    \n",
    "    # Stop the simulation if the blocking probability is higher than 1%\n",
    "    if bp_current > 0.01:\n",
    "        break\n",
    "end_time0 = time.time()\n",
    "print(\"Total time to compute is {:.2f} min\".format((end_time0-start_time0)/60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "name = ALGORITHM + '_' + PARTITIONING + '_' + TOPOLOGY\n",
    "\n",
    "# Append the border value hyperparameter if hard partitioning is used\n",
    "if PARTITIONING == 'Hard':\n",
    "    name+= ('_' + str(border))\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "df.to_csv('results/'+name+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nokiaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
